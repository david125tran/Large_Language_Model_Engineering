# -*- coding: utf-8 -*-
"""Day12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sZqTqd0g1zxBYAAzbDFVJ6sPT0hKlhgN

# üåü HuggingFace Transformers Library

üîó [https://huggingface.co](https://huggingface.co)

The HuggingFace Transformers library provides APIs at two different levels to make working with state-of-the-art models easier.

---

## üöÄ High-Level API: `pipeline`

The high-level API for using open-source models for typical inference tasks is called **`pipeline`**.

You can create and use a pipeline with just a few lines of code:

```python
from transformers import pipeline

# Define the task you want to perform
my_pipeline = pipeline("the_task_I_want_to_do")

# Run the pipeline on your input
result = my_pipeline(my_input)

üõë Common Runtime Error in Google Colab

While running a notebook, you might encounter an error like this:

Runtime error: CUDA is required but not available for bitsandbytes. Please consider installing [...]

    ‚ö†Ô∏è Don‚Äôt be misled!
    This message might suggest that a package version issue is the cause, but that‚Äôs usually not true.

üí° What‚Äôs Actually Happening:

Google Colab may silently switch your runtime environment‚Äîespecially during high demand. This results in losing access to the GPU, which triggers that misleading error.  
  
‚úÖ How to Fix It

Follow these steps to resolve the issue:

    Kernel menu ‚Üí Disconnect and delete runtime

    Reload the Colab notebook

    Edit menu ‚Üí Clear all outputs

    Reconnect to a GPU:

        Click the "Connect" button in the top-right corner

        Select "Change runtime type" if needed, and ensure GPU is selected

    Confirm GPU availability:

        Click "View resources" in the top-right menu

        Check that a GPU (like a T4) is listed

    Rerun all cells from the top, starting with the pip install commands

üß† Pro Tip: Always run the install and setup cells at the beginning after resetting the runtime to ensure everything loads correctly.

# üî• All Available Pipelines

Here‚Äôs a list of all the pipelines available from **Transformers** and **Diffusers**.

---

### üåü Transformers Pipelines
You can explore the available pipelines under the *Tasks* section on the HuggingFace Transformers documentation page.

- Visit: [Transformers Pipelines Documentation](https://huggingface.co/docs/transformers/main_classes/pipelines)
- Scroll down a bit, and expand the **parameters** section to see the list of **Tasks**.

### üåü Diffusion Pipelines
In case you‚Äôre interested in **Diffusion models** (e.g., image generation tasks), here‚Äôs the list for those.

- Visit: [Diffusers Pipelines Documentation](https://huggingface.co/docs/diffusers/en/api/pipelines/overview)

---

If you come across any cool examples of other pipelines, **please share them** with me! It‚Äôs amazing how HuggingFace makes this **advanced AI functionality** available for inference with such a **simple API**. ü§ñ‚ú®
"""

# ------------------------------------ Packages ----------------------------------!
!pip install -q -U transformers datasets diffusers

# ------------------------------------ Imports ----------------------------------
import torch
from google.colab import userdata
from huggingface_hub import login
from transformers import pipeline
from diffusers import DiffusionPipeline
from datasets import load_dataset
import soundfile as sf
from IPython.display import Audio

# ------------------------------------ Configure API Keys / Tokens ----------------------------------
# Retrieve stored API keys from Colab's secure userdata store
openai_api_key = userdata.get('OPENAI_API_KEY')
anthropic_api_key = userdata.get('ANTHROPIC_API_KEY')
google_api_key = userdata.get('GOOGLE_API_KEY')
hf_token = userdata.get('HF_TOKEN')

print("API Keys:")
if openai_api_key:
    print(f"OpenAI API Key exists and begins {openai_api_key[:10]}")
else:
    print("OpenAI API Key not set")

if anthropic_api_key:
    print(f"Anthropic API Key exists and begins {anthropic_api_key[:10]}")
else:
    print("Anthropic API Key not set")
if google_api_key:
    print(f"Google API Key exists and begins {google_api_key[:10]}")
else:
    print("Google API Key not set")
if hf_token:
    print(f"Hugging Face Token exists and begins {hf_token[:10]}")
else:
  print("Hugging Face Token not set")

# ------------------------------------ Connect to Hugging Face ----------------------------------
login(hf_token, add_to_git_credential=True)

# Request Access to HuggingFace Model:
# https://huggingface.co/black-forest-labs/FLUX.1-schnell

# ------------------------------------ Sentiment Analysis ----------------------------------
classifier = pipeline("sentiment-analysis", device="cuda")
result = classifier("I'm super excited to go eat at Larry's Steakhouse!")
print(result)

# ------------------------------------ Name Entity Recognition (ner) ----------------------------------
ner = pipeline("ner", grouped_entities=True, device="cuda")
result = ner("Barack Obama was the 44th president of the United States.")
print(result)

# ------------------------------------ Question Answering with Context ----------------------------------
question_answerer = pipeline("question-answering", device="cuda")
result = question_answerer(question="Who found dinosaur bones in Raleigh, NC in 2023?", context="David Tran found dinosaur fossils in Raleigh, NC in 2023.")
print(result)

# ------------------------------------ Text Summarization ----------------------------------
summarizer = pipeline("summarization", device="cuda")
text = """Common art themes reflect universal human experiences and concerns, transcending time and culture.
These often include the human condition, exploring aspects of identity, emotion, life, and death. Nature is
another pervasive theme, depicted in landscapes, seascapes, or as a symbol of growth, decay, or the sublime.
Religion and spirituality have historically been dominant, portraying deities, sacred narratives, and the
search for meaning. Social and political commentary frequently emerges, addressing conflict, injustice,
freedom, or the power dynamics within society. Finally, storytelling and history remain vital, with art
serving as a record of significant events, myths, and personal narratives.
"""
summary = summarizer(text, max_length=50, min_length=25, do_sample=False)
print(summary[0]['summary_text'])

# ------------------------------------ Translation ----------------------------------
translator = pipeline("translation_en_to_fr", device="cuda")
result = translator("The finest Sushi in North Carolina is actually in a restaurant located inside of a gas station!")
print(result[0]['translation_text'])

# ------------------------------------ Translation w/a Specified Model ----------------------------------
translator = pipeline("translation_en_to_es", model="Helsinki-NLP/opus-mt-en-es", device="cuda")
result = translator("The finest Sushi in North Carolina is actually in a restaurant located inside of a gas station!")
print(result[0]['translation_text'])

# ------------------------------------ Classification ----------------------------------
classifier = pipeline("zero-shot-classification", device="cuda")
result = classifier("UFO reports are currently circulating in Raleigh, NC.", candidate_labels=["technology", "sports", "politics"])
print(result)

# ------------------------------------ Text Generation ----------------------------------
generator = pipeline("text-generation", device="cuda")
result = generator("If there's one thing I you should about using HuggingFace pipelines, it's")
print(result[0]['generated_text'])

# ------------------------------------ Image Generation ----------------------------------
image_gen = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2",
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16"
    ).to("cuda")

text = "A dog painting a picture of a fish, in the surreal style of Salvador Dali"
image = image_gen(prompt=text).images[0]
image

# ------------------------------------ Audio Generation ----------------------------------
synthesiser = pipeline("text-to-speech", "microsoft/speecht5_tts", device='cuda')

embeddings_dataset = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation")
speaker_embedding = torch.tensor(embeddings_dataset[7306]["xvector"]).unsqueeze(0)

speech = synthesiser("Hello World, from the Hugging Face pipeline!", forward_params={"speaker_embeddings": speaker_embedding})

sf.write("speech.wav", speech["audio"], samplerate=speech["sampling_rate"])
Audio("speech.wav")

